{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Mendr\n",
    "\n",
    "We propose Smart Mendr, a new classification Model that applies Ensemble Learning and Data-driven Rectification to handle both scenarios of inaccurate and incomplete supervision. An overview of the proposed method is illustrated in Figure 5.1. As the figure shows, the method has two phases. In the first phase, Smart Mendr applies a preliminary stage of ensemble learning to estimate the probability of each instance being mislabeled and produce initially weak labels for unlabeled data. However, to overcome the challenges of noise detection using ensemble learning, we apply a semi-supervised learning approach to combine the output of the ensemble and report the noisy points. After that, the proposed method, in the second phase, applies a smart correcting procedure using meta-active learning to provide true labels for both noisy and unlabeled points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T02:34:02.347553Z",
     "start_time": "2019-01-29T02:34:02.274196Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading and preparing the data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_folder, dataset_name, y_column):\n",
    "    p_path =  input_folder + \"//\" + dataset_name + \"_noisy.csv\"\n",
    "    u_path =  input_folder + \"//\" + dataset_name + \"_unlabeled.csv\"\n",
    "    original_path = input_folder + \"//\" + dataset_name + \".csv\"\n",
    "    original_data = pd.read_csv(original_path, sep=',')\n",
    "\n",
    "    df_p = pd.read_csv(p_path, sep=',')\n",
    "    ground_truth = df_p[y_column]\n",
    "    df_p = df_p.drop(y_column, axis = 1)\n",
    "    df_u = pd.read_csv(u_path, sep=',') \n",
    "    df_u = df_u.drop(y_column, axis = 1)\n",
    "\n",
    "    return df_p, df_u, ground_truth, original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p, df_u, ground_truth, original_data = load_data(\"datasets\", \"shoppers\", \"prediction\")\n",
    "\n",
    "\n",
    "DU = original_data\n",
    "DU.index = [x for x in range(1, len(DU)+1)]\n",
    "DU.index.name = 'index'\n",
    "obj_columns = DU.select_dtypes(['object']).columns    \n",
    "for col in obj_columns:\n",
    "    DU[col] = DU[col].astype('category')\n",
    "cat_columns = DU.select_dtypes(['category']).columns    \n",
    "DU[cat_columns] = DU[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "obj_columns = df_p.select_dtypes(['object']).columns    \n",
    "for col in obj_columns:\n",
    "    df_p[col] = df_p[col].astype('category')\n",
    "cat_columns = df_p.select_dtypes(['category']).columns    \n",
    "df_p[cat_columns] = df_p[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "\n",
    "obj_columns = df_u.select_dtypes(['object']).columns   \n",
    "for col in obj_columns:\n",
    "    df_u[col] = df_u[col].astype('category')\n",
    "cat_columns = df_u.select_dtypes(['category']).columns    \n",
    "df_u[cat_columns] = df_u[cat_columns].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning\n",
    "In this phase, the proposed method aims at detecting data points with noisy labels in Dp and producing initial labels for the unlabeled points in Du. Therefore, the phase employs a set of ensembles in two stages. In the first stage, a set of base learners are built to produce predictions for the data points in D. Then, the ensemble predictor is utilized in the second stage to detect noisy points Dnoise in Dp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(df_p, ground_truth)\n",
    "predictions_p = clf.predict(df_u)\n",
    "predictions_u = clf.predict(df_p)\n",
    "predictions = np.concatenate((predictions_u, predictions_p))\n",
    "\n",
    "original_p = ground_truth\n",
    "original_u = np.zeros(df_u.shape[0])\n",
    "original = np.concatenate((original_u, original_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "S = np.column_stack((predictions,original))\n",
    "S = S.astype(int)\n",
    "L_train= sparse.csr_matrix(S) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to combine the output of the ensemble_learner and generate an initial vector of probabilistic labels, we employ a generative model to learn the accuracies of the predictions in H_Best and produce a single probabilistic label for each data point in the unlabeled dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 2\n",
      "[1.49074684 0.03306396]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import smartmendr.ensemble_learner\n",
    "from smartmendr.ensemble_learner.util_ensemble import *\n",
    "\n",
    "global gen_model \n",
    "gen_model, gen_train_marginals = Fitting_Gen_Model(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T22:23:27.847504Z",
     "start_time": "2019-01-28T22:23:27.643505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.955861</td>\n",
       "      <td>0.8224</td>\n",
       "      <td>0.957026</td>\n",
       "      <td>0.792959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.520830</td>\n",
       "      <td>0.6649</td>\n",
       "      <td>0.517097</td>\n",
       "      <td>0.344869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Coverage  Precision    Recall\n",
       "0  0.955861    0.8224   0.957026  0.792959\n",
       "1  0.520830    0.6649   0.517097  0.344869"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = gen_model.predictions(L_train, batch_size=None)\n",
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', 'ground_truth'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_list = DU.columns\n",
    "columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(gen_train_marginals.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_labeling_accuracy(threeshold, columns_list, train_marginals, df_original):\n",
    "    id_list = df_original.index\n",
    "    df_verify = df_original\n",
    "    \n",
    "\n",
    "    #df_verify ['index'] = id_list\n",
    "    df_verify ['Label'] = train_marginals.tolist()\n",
    "\n",
    "    df_verify.loc[df_verify ['Label'] >= threeshold, 'Label'] = 1\n",
    "    df_verify.loc[df_verify ['Label'] < threeshold, 'Label'] = -1\n",
    "\n",
    "    df_copy = df_original\n",
    "    df_copy = df_copy.drop(columns_list, axis = 1)\n",
    "\n",
    "    #print (\"1- df_copy columns\")\n",
    "    #print (df_copy.columns)\n",
    "    #calculating the labeling accuracy\n",
    "    counter = 0\n",
    "    for index, row in df_verify.iterrows():\n",
    "        if row['Label'] == float(row['ground_truth']):\n",
    "            counter = counter+1\n",
    "\n",
    "    labeling_accuracy = float(counter)/len(id_list)\n",
    "    return labeling_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41898148148148145\n"
     ]
    }
   ],
   "source": [
    "noise_detection = Calculate_labeling_accuracy(0.5, columns_list, gen_train_marginals, DU)\n",
    "print(noise_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstain = 0\n",
    "agreements_list=[]\n",
    "for rows in L_train:\n",
    "    if len(rows.data) == 0:\n",
    "        abstain=abstain+1      \n",
    "    agreements_list.append(abs(sum(rows.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-driven Active Learner\n",
    "The component tries to integrate the user in the loop at this point by employing active learning. However, our problem settings do not impose traditional active learning scenarios where we usually have a small set of labeled points and a larger set of unlabeled data. Instead, we deal with a set of probabilistic labels that are classified based on the confidence of the generative model. Therefore, we adopt meta-active learning in this component and apply a data-driven approach to learn the query strategy. The approach formulates the process of designing the query strategy as a regression problem. We train a regression model to predict the reduction of the generalization error associated with adding a labeled point {xi, yi} to the training data of a classifier. Our main hypothesis is that this regressor can serve as the query strategy in our problem settings to outperform the baseline strategies since it is customized to the underlying distribution and considers the output of the generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "agreements_list=[]\n",
    "unlabeled_list=[]\n",
    "i = 1\n",
    "for rows in L_train:\n",
    "    index_list.append(i)\n",
    "    if len(rows.data) == 0:\n",
    "        unlabeled_list.append(True)\n",
    "    else:\n",
    "        unlabeled_list.append(False)\n",
    "    agreements_list.append(abs(sum(rows.data)))\n",
    "    i=i+1\n",
    "    \n",
    "df_with_additional_info = pd.DataFrame(index_list)\n",
    "df_with_additional_info.columns=['index']\n",
    "df_with_additional_info['disagreement_factor'] = agreements_list\n",
    "df_with_additional_info['unlabeled_flag'] = unlabeled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_additional_info=df_with_additional_info.rename(columns={'index': 'index'})\n",
    "original_data = DU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_additional_info = df_with_additional_info.merge(original_data, on=['index'], how='left', indicator= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with additional info: disagreements and abstain\n",
      "(432, 12)\n",
      "Data for Active learning: Data with additional info after applying conditions\n",
      "(432, 12)\n"
     ]
    }
   ],
   "source": [
    "cond1 = df_with_additional_info['unlabeled_flag'] == True\n",
    "cond2 = df_with_additional_info['disagreement_factor'] <= 2\n",
    "df_active_learning= df_with_additional_info[cond1 | cond2]\n",
    "print(\"Data with additional info: disagreements and abstain\")\n",
    "print(df_with_additional_info.shape)\n",
    "print(\"Data for Active learning: Data with additional info after applying conditions\")\n",
    "print(df_active_learning.shape)\n",
    "df_active_learning = df_active_learning.drop(['unlabeled_flag', 'disagreement_factor', '_merge'], axis=1)\n",
    "df_active_learning['prediction'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index           int32\n",
       "0               int32\n",
       "1               int32\n",
       "2               int32\n",
       "3               int32\n",
       "4               int32\n",
       "5               int32\n",
       "ground_truth    int32\n",
       "Label           int32\n",
       "prediction      int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_active_learning = df_active_learning.fillna(0)\n",
    "df_active_learning.replace([np.inf, -np.inf], np.nan)\n",
    "df_active_learning.astype('int32').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_variable = 0.7\n",
    "labeling_budget = int(budget_variable*len(df_with_additional_info.index))\n",
    "if(labeling_budget >= df_active_learning.shape[0]):\n",
    "    labeling_budget= int(1*len(df_active_learning.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=40,\n",
       "           max_features=6, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=1000, n_jobs=8, oob_score=True, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from data_learner.active_learner import *\n",
    "from data_learner.models import DDL_Dataset \n",
    "from data_learner.lal_model import LALmodel\n",
    "\n",
    "fn = 'LAL-iterativetree-simulatedunbalanced-big.npz'\n",
    "parameters = {'est': 1000, 'depth': 40, 'feat': 6 }\n",
    "filename = '../smartmendr/data_learner/datasets/'+fn\n",
    "regression_data = np.load(filename)\n",
    "regression_features = regression_data['arr_0']\n",
    "regression_labels = regression_data['arr_1']\n",
    "lalModel = RandomForestRegressor(n_estimators = parameters['est'], max_depth = parameters['depth'], \n",
    "                                 max_features=parameters['feat'], oob_score=True, n_jobs=8)\n",
    "lalModel.fit(regression_features, np.ravel(regression_labels))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   3.   3. ...   1.  -1.  -1.]\n",
      " [  2.   1.   1. ...   2.  -1.  -1.]\n",
      " [  3.   2.   3. ...   1.  -1.  -1.]\n",
      " ...\n",
      " [343.   3.   2. ...   1.   1.  -1.]\n",
      " [344.   3.   2. ...   1.   1.  -1.]\n",
      " [345.   1.   1. ...   1.   1.  -1.]]\n",
      "final results:\n",
      "-----------------\n",
      "[ 38.   7. 106. 264.   5. 202.  68.  11.  88. 194.  22.  98.  45. 293.\n",
      " 241. 101. 223.  26.  57.  37.  67.  20. 324. 190.  18.  10.  19.  47.\n",
      " 274.   9.  21.  14. 271.  87. 282.  16.  39. 136. 215.  12. 320.  28.\n",
      "   3.  55.   6.  29.  41.  35.   4.   2.  43. 178.  13.  62. 206.  25.\n",
      " 159.  72. 153.  48.   8.  78.  70.  15.  63.  65.  84. 212.  76.  49.\n",
      "  31.  83. 148.  75. 151.  77.  71.  85.  40. 167.  23. 152. 157.  92.\n",
      " 158. 168.  30.  79. 145. 160.  64.  69.  32.  24.  97. 341.  27.  36.\n",
      "  34.  86.  73.  80. 149.  61. 150.  66.  74.  81.  82.  42.  44. 154.\n",
      "  52.  33. 179. 155. 232.  50. 156. 165. 169.  51.  46.  53. 161.  59.\n",
      " 100. 162.  96. 170. 171.  95. 135. 163.  90. 164.  58.  94. 187.  54.\n",
      " 123.  93. 166.  99. 172. 173. 138. 108. 174. 245. 177. 122.  89.  91.\n",
      " 175. 188. 184. 265. 112. 292. 176. 181. 247. 236. 235. 237. 139. 244.\n",
      " 238. 200. 243. 246. 132. 248. 239. 182. 240. 125. 242. 249. 185. 252.\n",
      "  56.  60. 250. 183. 124. 251. 254. 253. 118. 116. 180. 255. 110. 257.\n",
      " 147. 102. 258. 272. 256. 225. 259. 260. 262. 120. 134. 266. 268. 275.\n",
      " 269. 121. 107. 143. 119. 273. 331. 186. 195. 330. 261. 322. 345. 325.\n",
      " 328. 323. 270. 326. 327. 329. 193. 263. 221. 332. 334. 333. 335. 336.\n",
      " 337. 338. 342. 344. 208. 340. 231. 339. 343. 234. 111. 230. 217. 288.\n",
      " 210. 309. 267. 312. 128. 299. 130. 209. 301. 214. 296. 105. 198. 114.\n",
      " 126. 113. 318. 117. 276. 220. 211. 129. 203. 304. 103. 127. 191. 192.\n",
      " 196. 303. 137. 321. 115. 140. 228. 104. 109. 207. 144. 216. 306. 131.\n",
      " 218. 205. 146. 278. 277. 222.]\n",
      "[ 1. -1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.\n",
      "  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1. -1.\n",
      "  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1. -1. -1.  1. -1. -1. -1.\n",
      "  1.  1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1.\n",
      " -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.  1. -1.  1. -1.\n",
      " -1. -1.  1.  1. -1. -1.  1.  1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.\n",
      " -1.  1.  1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1.  1.\n",
      " -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.\n",
      " -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1.  1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1.  1. -1.  1.  1.\n",
      " -1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1.  1.  1.  1. -1.\n",
      " -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1.  1.  1.  1.  1.  1.\n",
      "  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "from smartmendr.data_learner.dl_utils import *\n",
    "indices, labels= run_dll(lalModel, labeling_budget,df_active_learning);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_Results=pd.DataFrame(columns=['index','AL_Label'])\n",
    "AL_Results['index']=indices.astype('int64')\n",
    "AL_Results['AL_Label']=labels\n",
    "AL_Results = AL_Results.sort_values(by =['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mona/.local/lib/python3.6/site-packages/scipy/sparse/_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5446955  1.52143692]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "AL_Results.loc[AL_Results['AL_Label']==0, 'AL_Label']=-1\n",
    "data_with_AL_Results = df_with_additional_info.merge(AL_Results, on=['index'], how='left')\n",
    "true_label = data_with_AL_Results['AL_Label']\n",
    "true_label = true_label.fillna(0)\n",
    "for i in range(len(true_label)):\n",
    "    if true_label[i] !=0:\n",
    "        L_train[i,:]=true_label[i]\n",
    "gen_model, AL_train_marginals = Fitting_Gen_Model(L_train)\n",
    "predictions = gen_model.predictions(L_train, batch_size=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5185185185185185\n"
     ]
    }
   ],
   "source": [
    "columns_list\n",
    "noise_detection = Calculate_labeling_accuracy(0.5, columns_list, AL_train_marginals, DU)\n",
    "print(noise_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
