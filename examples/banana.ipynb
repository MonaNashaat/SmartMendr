{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Mendr\n",
    "\n",
    "We propose Smart Mendr, a new classification Model that applies Ensemble Learning and Data-driven Rectification to handle both scenarios of inaccurate and incomplete supervision. An overview of the proposed method is illustrated in Figure 5.1. As the figure shows, the method has two phases. In the first phase, Smart Mendr applies a preliminary stage of ensemble learning to estimate the probability of each instance being mislabeled and produce initially weak labels for unlabeled data. However, to overcome the challenges of noise detection using ensemble learning, we apply a semi-supervised learning approach to combine the output of the ensemble and report the noisy points. After that, the proposed method, in the second phase, applies a smart correcting procedure using meta-active learning to provide true labels for both noisy and unlabeled points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T02:34:02.347553Z",
     "start_time": "2019-01-29T02:34:02.274196Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading and preparing the data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_folder, dataset_name, y_column):\n",
    "    p_path =  input_folder + \"//\" + dataset_name + \"_noisy.csv\"\n",
    "    u_path =  input_folder + \"//\" + dataset_name + \"_unlabeled.csv\"\n",
    "    original_path = input_folder + \"//\" + dataset_name + \".csv\"\n",
    "    original_data = pd.read_csv(original_path, sep=',')\n",
    "\n",
    "    df_p = pd.read_csv(p_path, sep=',')\n",
    "    ground_truth = df_p[y_column]\n",
    "    df_p = df_p.drop(y_column, axis = 1)\n",
    "    df_u = pd.read_csv(u_path, sep=',') \n",
    "    df_u = df_u.drop(y_column, axis = 1)\n",
    "\n",
    "    return df_p, df_u, ground_truth, original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p, df_u, ground_truth, original_data = load_data(\"datasets\", \"Banana\", \"prediction\")\n",
    "\n",
    "\n",
    "DU = original_data\n",
    "DU.index = [x for x in range(1, len(DU)+1)]\n",
    "DU.index.name = 'index'\n",
    "obj_columns = DU.select_dtypes(['object']).columns    \n",
    "for col in obj_columns:\n",
    "    DU[col] = DU[col].astype('category')\n",
    "cat_columns = DU.select_dtypes(['category']).columns    \n",
    "DU[cat_columns] = DU[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "obj_columns = df_p.select_dtypes(['object']).columns    \n",
    "for col in obj_columns:\n",
    "    df_p[col] = df_p[col].astype('category')\n",
    "cat_columns = df_p.select_dtypes(['category']).columns    \n",
    "df_p[cat_columns] = df_p[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "\n",
    "obj_columns = df_u.select_dtypes(['object']).columns   \n",
    "for col in obj_columns:\n",
    "    df_u[col] = df_u[col].astype('category')\n",
    "cat_columns = df_u.select_dtypes(['category']).columns    \n",
    "df_u[cat_columns] = df_u[cat_columns].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning\n",
    "In this phase, the proposed method aims at detecting data points with noisy labels in Dp and producing initial labels for the unlabeled points in Du. Therefore, the phase employs a set of ensembles in two stages. In the first stage, a set of base learners are built to produce predictions for the data points in D. Then, the ensemble predictor is utilized in the second stage to detect noisy points Dnoise in Dp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(df_p, ground_truth)\n",
    "predictions_p = clf.predict(df_u)\n",
    "predictions_u = clf.predict(df_p)\n",
    "predictions = np.concatenate((predictions_u, predictions_p))\n",
    "\n",
    "original_p = ground_truth\n",
    "original_u = np.zeros(df_u.shape[0])\n",
    "original = np.concatenate((original_u, original_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "S = np.column_stack((predictions,original))\n",
    "S = S.astype(int)\n",
    "L_train= sparse.csr_matrix(S) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5297, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to combine the output of the ensemble_learner and generate an initial vector of probabilistic labels, we employ a generative model to learn the accuracies of the predictions in H_Best and produce a single probabilistic label for each data point in the unlabeled dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 2\n",
      "[1.54208115 0.14582523]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import smartmendr.ensemble_learner\n",
    "from smartmendr.ensemble_learner.util_ensemble import *\n",
    "\n",
    "global gen_model \n",
    "gen_model, gen_train_marginals = Fitting_Gen_Model(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T22:23:27.847504Z",
     "start_time": "2019-01-28T22:23:27.643505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.955539</td>\n",
       "      <td>0.8277</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.793232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.567414</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>0.577388</td>\n",
       "      <td>0.375762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Coverage  Precision    Recall\n",
       "0  0.955539    0.8277   0.957265  0.793232\n",
       "1  0.567414    0.6690   0.577388  0.375762"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = gen_model.predictions(L_train, batch_size=None)\n",
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstain = 0\n",
    "agreements_list=[]\n",
    "for rows in L_train:\n",
    "    if len(rows.data) == 0:\n",
    "        abstain=abstain+1      \n",
    "    agreements_list.append(abs(sum(rows.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-driven Active Learner\n",
    "The component tries to integrate the user in the loop at this point by employing active learning. However, our problem settings do not impose traditional active learning scenarios where we usually have a small set of labeled points and a larger set of unlabeled data. Instead, we deal with a set of probabilistic labels that are classified based on the confidence of the generative model. Therefore, we adopt meta-active learning in this component and apply a data-driven approach to learn the query strategy. The approach formulates the process of designing the query strategy as a regression problem. We train a regression model to predict the reduction of the generalization error associated with adding a labeled point {xi, yi} to the training data of a classifier. Our main hypothesis is that this regressor can serve as the query strategy in our problem settings to outperform the baseline strategies since it is customized to the underlying distribution and considers the output of the generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "agreements_list=[]\n",
    "unlabeled_list=[]\n",
    "i = 1\n",
    "for rows in L_train:\n",
    "    index_list.append(i)\n",
    "    if len(rows.data) == 0:\n",
    "        unlabeled_list.append(True)\n",
    "    else:\n",
    "        unlabeled_list.append(False)\n",
    "    agreements_list.append(abs(sum(rows.data)))\n",
    "    i=i+1\n",
    "    \n",
    "df_with_additional_info = pd.DataFrame(index_list)\n",
    "df_with_additional_info.columns=['index']\n",
    "df_with_additional_info['disagreement_factor'] = agreements_list\n",
    "df_with_additional_info['unlabeled_flag'] = unlabeled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_additional_info=df_with_additional_info.rename(columns={'index': 'index'})\n",
    "original_data = DU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_additional_info = df_with_additional_info.merge(original_data, on=['index'], how='left', indicator= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with additional info: disagreements and abstain\n",
      "(5297, 7)\n",
      "Data for Active learning: Data with additional info after applying conditions\n",
      "(5297, 7)\n"
     ]
    }
   ],
   "source": [
    "cond1 = df_with_additional_info['unlabeled_flag'] == True\n",
    "cond2 = df_with_additional_info['disagreement_factor'] <= 2\n",
    "df_active_learning= df_with_additional_info[cond1 | cond2]\n",
    "print(\"Data with additional info: disagreements and abstain\")\n",
    "print(df_with_additional_info.shape)\n",
    "print(\"Data for Active learning: Data with additional info after applying conditions\")\n",
    "print(df_active_learning.shape)\n",
    "df_active_learning = df_active_learning.drop(['unlabeled_flag', 'disagreement_factor', '_merge'], axis=1)\n",
    "df_active_learning['prediction'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>disagreement_factor</th>\n",
       "      <th>unlabeled_flag</th>\n",
       "      <th>At1</th>\n",
       "      <th>At2</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.1400</td>\n",
       "      <td>-0.11400</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.5200</td>\n",
       "      <td>-1.15000</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0500</td>\n",
       "      <td>0.72000</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.9160</td>\n",
       "      <td>0.39700</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0900</td>\n",
       "      <td>0.43700</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.5840</td>\n",
       "      <td>0.09370</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.8300</td>\n",
       "      <td>0.45200</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.2500</td>\n",
       "      <td>-0.28600</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>1.21000</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.4820</td>\n",
       "      <td>-0.48500</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.7900</td>\n",
       "      <td>-0.45900</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.1220</td>\n",
       "      <td>-0.80800</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0809</td>\n",
       "      <td>1.93000</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.5410</td>\n",
       "      <td>-0.33200</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0200</td>\n",
       "      <td>0.61900</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.7680</td>\n",
       "      <td>-1.04000</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.6900</td>\n",
       "      <td>-0.04610</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2600</td>\n",
       "      <td>1.21000</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7240</td>\n",
       "      <td>0.98900</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.4440</td>\n",
       "      <td>1.99000</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0100</td>\n",
       "      <td>-1.36000</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.8630</td>\n",
       "      <td>0.49600</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.1600</td>\n",
       "      <td>-0.45800</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.5950</td>\n",
       "      <td>-0.65100</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.7700</td>\n",
       "      <td>0.36400</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.8710</td>\n",
       "      <td>-0.82500</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>-1.70000</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2800</td>\n",
       "      <td>0.69100</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.89500</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.6870</td>\n",
       "      <td>-1.29000</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>5268</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.1300</td>\n",
       "      <td>0.41100</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>5269</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.8720</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>5270</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.4150</td>\n",
       "      <td>0.25600</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>5271</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8010</td>\n",
       "      <td>-0.63900</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>5272</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7620</td>\n",
       "      <td>0.12500</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>5273</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>-1.18000</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5273</th>\n",
       "      <td>5274</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5240</td>\n",
       "      <td>-0.23100</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>5275</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.0262</td>\n",
       "      <td>-1.18000</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5275</th>\n",
       "      <td>5276</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.4700</td>\n",
       "      <td>-0.03580</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5276</th>\n",
       "      <td>5277</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2900</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>5278</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.8510</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>5279</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.9610</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>5280</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.7760</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>5281</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.6740</td>\n",
       "      <td>-0.62000</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>5282</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>-0.69000</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5282</th>\n",
       "      <td>5283</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.9740</td>\n",
       "      <td>0.51100</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5283</th>\n",
       "      <td>5284</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>1.03000</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5284</th>\n",
       "      <td>5285</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.9800</td>\n",
       "      <td>-0.88000</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>5286</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>5287</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.6200</td>\n",
       "      <td>0.46800</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>5288</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.8430</td>\n",
       "      <td>-1.08000</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5288</th>\n",
       "      <td>5289</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.17000</td>\n",
       "      <td>-1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>5290</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.9540</td>\n",
       "      <td>0.68700</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>5291</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7680</td>\n",
       "      <td>-0.96600</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>5292</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.6400</td>\n",
       "      <td>1.12000</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292</th>\n",
       "      <td>5293</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.7000</td>\n",
       "      <td>-0.55400</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5293</th>\n",
       "      <td>5294</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.4040</td>\n",
       "      <td>0.00999</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5294</th>\n",
       "      <td>5295</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7040</td>\n",
       "      <td>-0.90600</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5295</th>\n",
       "      <td>5296</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>1.39000</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296</th>\n",
       "      <td>5297</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.7000</td>\n",
       "      <td>-0.56900</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5297 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  disagreement_factor  unlabeled_flag     At1      At2  \\\n",
       "0         1                    1           False  1.1400 -0.11400   \n",
       "1         2                    1           False -1.5200 -1.15000   \n",
       "2         3                    1           False -1.0500  0.72000   \n",
       "3         4                    1           False -0.9160  0.39700   \n",
       "4         5                    1           False -1.0900  0.43700   \n",
       "5         6                    1           False -0.5840  0.09370   \n",
       "6         7                    1           False  1.8300  0.45200   \n",
       "7         8                    1           False -1.2500 -0.28600   \n",
       "8         9                    1           False  1.7000  1.21000   \n",
       "9        10                    1           False -0.4820 -0.48500   \n",
       "10       11                    1           False  1.7900 -0.45900   \n",
       "11       12                    1           False -0.1220 -0.80800   \n",
       "12       13                    1           False  0.0809  1.93000   \n",
       "13       14                    1           False -0.5410 -0.33200   \n",
       "14       15                    1           False -1.0200  0.61900   \n",
       "15       16                    1           False -0.7680 -1.04000   \n",
       "16       17                    1           False -1.6900 -0.04610   \n",
       "17       18                    1           False  1.2600  1.21000   \n",
       "18       19                    1           False  0.7240  0.98900   \n",
       "19       20                    1           False  0.4440  1.99000   \n",
       "20       21                    1           False -1.0100 -1.36000   \n",
       "21       22                    1           False -0.8630  0.49600   \n",
       "22       23                    1           False  1.1600 -0.45800   \n",
       "23       24                    1           False -0.5950 -0.65100   \n",
       "24       25                    1           False -0.7700  0.36400   \n",
       "25       26                    1           False -0.8710 -0.82500   \n",
       "26       27                    1           False  0.9960 -1.70000   \n",
       "27       28                    1           False  1.2800  0.69100   \n",
       "28       29                    1           False  0.9250  0.89500   \n",
       "29       30                    1           False -0.6870 -1.29000   \n",
       "...     ...                  ...             ...     ...      ...   \n",
       "5267   5268                    0           False -1.1300  0.41100   \n",
       "5268   5269                    0           False -0.8720  0.26000   \n",
       "5269   5270                    0           False -0.4150  0.25600   \n",
       "5270   5271                    2           False  0.8010 -0.63900   \n",
       "5271   5272                    0           False  0.7620  0.12500   \n",
       "5272   5273                    2           False  0.0343 -1.18000   \n",
       "5273   5274                    0           False  0.5240 -0.23100   \n",
       "5274   5275                    2           False -0.0262 -1.18000   \n",
       "5275   5276                    2           False -1.4700 -0.03580   \n",
       "5276   5277                    0           False  1.2900  0.15200   \n",
       "5277   5278                    0           False -0.8510  0.18900   \n",
       "5278   5279                    2           False -0.9610  1.00000   \n",
       "5279   5280                    0           False -0.7760  0.12700   \n",
       "5280   5281                    0           False -0.6740 -0.62000   \n",
       "5281   5282                    0           False  0.2440 -0.69000   \n",
       "5282   5283                    0           False -0.9740  0.51100   \n",
       "5283   5284                    0           False  0.3700  1.03000   \n",
       "5284   5285                    0           False -1.9800 -0.88000   \n",
       "5285   5286                    0           False  0.3080  0.11700   \n",
       "5286   5287                    0           False -1.6200  0.46800   \n",
       "5287   5288                    2           False -0.8430 -1.08000   \n",
       "5288   5289                    0           False  1.0000  1.17000   \n",
       "5289   5290                    0           False -0.9540  0.68700   \n",
       "5290   5291                    0           False  0.7680 -0.96600   \n",
       "5291   5292                    0           False  1.6400  1.12000   \n",
       "5292   5293                    2           False -1.7000 -0.55400   \n",
       "5293   5294                    2           False  0.4040  0.00999   \n",
       "5294   5295                    0           False  0.7040 -0.90600   \n",
       "5295   5296                    0           False  0.3350  1.39000   \n",
       "5296   5297                    2           False -1.7000 -0.56900   \n",
       "\n",
       "      ground_truth _merge  \n",
       "0               -1   both  \n",
       "1                1   both  \n",
       "2               -1   both  \n",
       "3                1   both  \n",
       "4                1   both  \n",
       "5                1   both  \n",
       "6               -1   both  \n",
       "7                1   both  \n",
       "8                1   both  \n",
       "9                1   both  \n",
       "10              -1   both  \n",
       "11              -1   both  \n",
       "12               1   both  \n",
       "13               1   both  \n",
       "14              -1   both  \n",
       "15              -1   both  \n",
       "16               1   both  \n",
       "17               1   both  \n",
       "18              -1   both  \n",
       "19              -1   both  \n",
       "20              -1   both  \n",
       "21               1   both  \n",
       "22               1   both  \n",
       "23               1   both  \n",
       "24               1   both  \n",
       "25               1   both  \n",
       "26               1   both  \n",
       "27              -1   both  \n",
       "28              -1   both  \n",
       "29              -1   both  \n",
       "...            ...    ...  \n",
       "5267             1   both  \n",
       "5268             1   both  \n",
       "5269             1   both  \n",
       "5270             1   both  \n",
       "5271             1   both  \n",
       "5272            -1   both  \n",
       "5273             1   both  \n",
       "5274            -1   both  \n",
       "5275             1   both  \n",
       "5276            -1   both  \n",
       "5277             1   both  \n",
       "5278            -1   both  \n",
       "5279             1   both  \n",
       "5280             1   both  \n",
       "5281             1   both  \n",
       "5282             1   both  \n",
       "5283            -1   both  \n",
       "5284             1   both  \n",
       "5285             1   both  \n",
       "5286            -1   both  \n",
       "5287            -1   both  \n",
       "5288            -1   both  \n",
       "5289             1   both  \n",
       "5290             1   both  \n",
       "5291             1   both  \n",
       "5292             1   both  \n",
       "5293             1   both  \n",
       "5294             1   both  \n",
       "5295             1   both  \n",
       "5296             1   both  \n",
       "\n",
       "[5297 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_additional_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_variable = 0.7\n",
    "labeling_budget = int(budget_variable*len(df_with_additional_info.index))\n",
    "if(labeling_budget >= df_active_learning.shape[0]):\n",
    "    labeling_budget= int(1*len(df_active_learning.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=40,\n",
       "           max_features=6, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=1000, n_jobs=8, oob_score=True, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from data_learner.active_learner import *\n",
    "from data_learner.models import DDL_Dataset \n",
    "from data_learner.lal_model import LALmodel\n",
    "\n",
    "fn = 'LAL-iterativetree-simulatedunbalanced-big.npz'\n",
    "parameters = {'est': 1000, 'depth': 40, 'feat': 6 }\n",
    "filename = '../smartmendr/data_learner/datasets/'+fn\n",
    "regression_data = np.load(filename)\n",
    "regression_features = regression_data['arr_0']\n",
    "regression_labels = regression_data['arr_1']\n",
    "lalModel = RandomForestRegressor(n_estimators = parameters['est'], max_depth = parameters['depth'], \n",
    "                                 max_features=parameters['feat'], oob_score=True, n_jobs=8)\n",
    "lalModel.fit(regression_features, np.ravel(regression_labels))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.000e+00  1.140e+00 -1.140e-01 -1.000e+00]\n",
      " [ 2.000e+00 -1.520e+00 -1.150e+00  1.000e+00]\n",
      " [ 3.000e+00 -1.050e+00  7.200e-01 -1.000e+00]\n",
      " ...\n",
      " [ 4.235e+03 -4.210e-01 -1.090e+00 -1.000e+00]\n",
      " [ 4.236e+03  8.490e-01  9.070e-01 -1.000e+00]\n",
      " [ 4.237e+03 -1.170e+00  1.080e+00 -1.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from smartmendr.data_learner.dl_utils import *\n",
    "indices, labels= run_dll(lalModel, labeling_budget,df_active_learning);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_Results=pd.DataFrame(columns=['index','AL_Label'])\n",
    "AL_Results['index']=indices.astype('int64')\n",
    "AL_Results['AL_Label']=labels\n",
    "AL_Results = AL_Results.sort_values(by =['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_Results.loc[AL_Results['AL_Label']==0, 'AL_Label']=-1\n",
    "data_with_AL_Results = df_with_additional_info.merge(AL_Results, on=['index'], how='left')\n",
    "true_label = data_with_AL_Results['AL_Label']\n",
    "true_label = true_label.fillna(0)\n",
    "for i in range(len(true_label)):\n",
    "    if true_label[i] !=0:\n",
    "        L_train[i,:]=true_label[i]\n",
    "gen_model, AL_train_marginals = Fitting_Gen_Model(L_train)\n",
    "predictions = gen_model.predictions(reef_L_train, batch_size=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(predictions, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
