{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Mendr\n",
    "\n",
    "We propose Smart Mendr, a new classification Model that applies Ensemble Learning and Data-driven Rectification to handle both scenarios of inaccurate and incomplete supervision. An overview of the proposed method is illustrated in Figure 5.1. As the figure shows, the method has two phases. In the first phase, Smart Mendr applies a preliminary stage of ensemble learning to estimate the probability of each instance being mislabeled and produce initially weak labels for unlabeled data. However, to overcome the challenges of noise detection using ensemble learning, we apply a semi-supervised learning approach to combine the output of the ensemble and report the noisy points. After that, the proposed method, in the second phase, applies a smart correcting procedure using meta-active learning to provide true labels for both noisy and unlabeled points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T02:34:02.347553Z",
     "start_time": "2019-01-29T02:34:02.274196Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading and preparing the data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_folder, dataset_name, y_column):\n",
    "    p_path =  input_folder + \"//\" + dataset_name + \"_noisy.csv\"\n",
    "    u_path =  input_folder + \"//\" + dataset_name + \"_unlabeled.csv\"\n",
    "    original_path = input_folder + \"//\" + dataset_name + \".csv\"\n",
    "    original_data = pd.read_csv(original_path, sep=',')\n",
    "\n",
    "    df_p = pd.read_csv(p_path, sep=',')\n",
    "    ground_truth = df_p[y_column]\n",
    "    df_p = df_p.drop(y_column, axis = 1)\n",
    "    df_u = pd.read_csv(u_path, sep=',') \n",
    "    df_u = df_u.drop(y_column, axis = 1)\n",
    "\n",
    "    return df_p, df_u, ground_truth, original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p, df_u, ground_truth, original_data = load_data(\"datasets\", \"census\", \"prediction\")\n",
    "\n",
    "\n",
    "DU = original_data\n",
    "DU.index = [x for x in range(1, len(DU)+1)]\n",
    "DU.index.name = 'index'\n",
    "obj_columns = DU.select_dtypes(['object']).columns    \n",
    "for col in obj_columns:\n",
    "    DU[col] = DU[col].astype('category')\n",
    "cat_columns = DU.select_dtypes(['category']).columns    \n",
    "DU[cat_columns] = DU[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "obj_columns = df_p.select_dtypes(['object']).columns    \n",
    "for col in obj_columns:\n",
    "    df_p[col] = df_p[col].astype('category')\n",
    "cat_columns = df_p.select_dtypes(['category']).columns    \n",
    "df_p[cat_columns] = df_p[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "\n",
    "obj_columns = df_u.select_dtypes(['object']).columns   \n",
    "for col in obj_columns:\n",
    "    df_u[col] = df_u[col].astype('category')\n",
    "cat_columns = df_u.select_dtypes(['category']).columns    \n",
    "df_u[cat_columns] = df_u[cat_columns].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning\n",
    "In this phase, the proposed method aims at detecting data points with noisy labels in Dp and producing initial labels for the unlabeled points in Du. Therefore, the phase employs a set of ensembles in two stages. In the first stage, a set of base learners are built to produce predictions for the data points in D. Then, the ensemble predictor is utilized in the second stage to detect noisy points Dnoise in Dp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(df_p, ground_truth)\n",
    "predictions_p = clf.predict(df_u)\n",
    "predictions_u = clf.predict(df_p)\n",
    "predictions = np.concatenate((predictions_u, predictions_p))\n",
    "\n",
    "original_p = ground_truth\n",
    "original_u = np.zeros(df_u.shape[0])\n",
    "original = np.concatenate((original_u, original_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "S = np.column_stack((predictions,original))\n",
    "S = S.astype(int)\n",
    "L_train= sparse.csr_matrix(S) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to combine the output of the ensemble_learner and generate an initial vector of probabilistic labels, we employ a generative model to learn the accuracies of the predictions in H_Best and produce a single probabilistic label for each data point in the unlabeled dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 2\n",
      "[1.65212065 0.20238998]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import smartmendr.ensemble_learner\n",
    "from smartmendr.ensemble_learner.util_ensemble import *\n",
    "\n",
    "global gen_model \n",
    "gen_model, gen_train_marginals = Fitting_Gen_Model(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T22:23:27.847504Z",
     "start_time": "2019-01-28T22:23:27.643505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.963397</td>\n",
       "      <td>0.818330</td>\n",
       "      <td>0.96613</td>\n",
       "      <td>0.8503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.594691</td>\n",
       "      <td>0.405202</td>\n",
       "      <td>0.60024</td>\n",
       "      <td>0.6669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision    Recall  Accuracy  Coverage\n",
       "0   0.963397  0.818330   0.96613    0.8503\n",
       "1   0.594691  0.405202   0.60024    0.6669"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = gen_model.predictions(L_train, batch_size=None)\n",
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
       "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
       "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
       "       'ground_truth'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_list = DU.columns\n",
    "columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(gen_train_marginals.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_labeling_accuracy(threeshold, columns_list, train_marginals, df_original):\n",
    "    id_list = df_original.index\n",
    "    df_verify = df_original\n",
    "    \n",
    "\n",
    "    #df_verify ['index'] = id_list\n",
    "    df_verify ['Label'] = train_marginals.tolist()\n",
    "\n",
    "    df_verify.loc[df_verify ['Label'] >= threeshold, 'Label'] = 1\n",
    "    df_verify.loc[df_verify ['Label'] < threeshold, 'Label'] = -1\n",
    "\n",
    "    df_copy = df_original\n",
    "    df_copy = df_copy.drop(columns_list, axis = 1)\n",
    "\n",
    "    #print (\"1- df_copy columns\")\n",
    "    #print (df_copy.columns)\n",
    "    #calculating the labeling accuracy\n",
    "    counter = 0\n",
    "    for index, row in df_verify.iterrows():\n",
    "        if row['Label'] == float(row['ground_truth']):\n",
    "            counter = counter+1\n",
    "\n",
    "    labeling_accuracy = float(counter)/len(id_list)\n",
    "    return labeling_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6548017567028039\n"
     ]
    }
   ],
   "source": [
    "noise_detection = Calculate_labeling_accuracy(0.5, columns_list, gen_train_marginals, DU)\n",
    "print(noise_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstain = 0\n",
    "agreements_list=[]\n",
    "for rows in L_train:\n",
    "    if len(rows.data) == 0:\n",
    "        abstain=abstain+1      \n",
    "    agreements_list.append(abs(sum(rows.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-driven Active Learner\n",
    "The component tries to integrate the user in the loop at this point by employing active learning. However, our problem settings do not impose traditional active learning scenarios where we usually have a small set of labeled points and a larger set of unlabeled data. Instead, we deal with a set of probabilistic labels that are classified based on the confidence of the generative model. Therefore, we adopt meta-active learning in this component and apply a data-driven approach to learn the query strategy. The approach formulates the process of designing the query strategy as a regression problem. We train a regression model to predict the reduction of the generalization error associated with adding a labeled point {xi, yi} to the training data of a classifier. Our main hypothesis is that this regressor can serve as the query strategy in our problem settings to outperform the baseline strategies since it is customized to the underlying distribution and considers the output of the generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "agreements_list=[]\n",
    "unlabeled_list=[]\n",
    "i = 1\n",
    "for rows in L_train:\n",
    "    index_list.append(i)\n",
    "    if len(rows.data) == 0:\n",
    "        unlabeled_list.append(True)\n",
    "    else:\n",
    "        unlabeled_list.append(False)\n",
    "    agreements_list.append(abs(sum(rows.data)))\n",
    "    i=i+1\n",
    "    \n",
    "df_with_additional_info = pd.DataFrame(index_list)\n",
    "df_with_additional_info.columns=['index']\n",
    "df_with_additional_info['disagreement_factor'] = agreements_list\n",
    "df_with_additional_info['unlabeled_flag'] = unlabeled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_additional_info=df_with_additional_info.rename(columns={'index': 'index'})\n",
    "original_data = DU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_additional_info = df_with_additional_info.merge(original_data, on=['index'], how='left', indicator= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with additional info: disagreements and abstain\n",
      "(32561, 20)\n",
      "Data for Active learning: Data with additional info after applying conditions\n",
      "(32561, 20)\n"
     ]
    }
   ],
   "source": [
    "cond1 = df_with_additional_info['unlabeled_flag'] == True\n",
    "cond2 = df_with_additional_info['disagreement_factor'] <= 2\n",
    "df_active_learning= df_with_additional_info[cond1 | cond2]\n",
    "print(\"Data with additional info: disagreements and abstain\")\n",
    "print(df_with_additional_info.shape)\n",
    "print(\"Data for Active learning: Data with additional info after applying conditions\")\n",
    "print(df_active_learning.shape)\n",
    "df_active_learning = df_active_learning.drop(['unlabeled_flag', 'disagreement_factor', '_merge'], axis=1)\n",
    "df_active_learning['prediction'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index             int32\n",
       "age               int32\n",
       "workclass         int32\n",
       "fnlwgt            int32\n",
       "education         int32\n",
       "education-num     int32\n",
       "marital-status    int32\n",
       "occupation        int32\n",
       "relationship      int32\n",
       "race              int32\n",
       "sex               int32\n",
       "capital-gain      int32\n",
       "capital-loss      int32\n",
       "hours-per-week    int32\n",
       "native-country    int32\n",
       "ground_truth      int32\n",
       "Label             int32\n",
       "prediction        int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_active_learning = df_active_learning.fillna(0)\n",
    "df_active_learning.replace([np.inf, -np.inf], np.nan)\n",
    "df_active_learning.astype('int32').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_variable = 0.7\n",
    "labeling_budget = int(budget_variable*len(df_with_additional_info.index))\n",
    "if(labeling_budget >= df_active_learning.shape[0]):\n",
    "    labeling_budget= int(1*len(df_active_learning.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=40, max_features=6, n_estimators=1000, n_jobs=8,\n",
       "                      oob_score=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from smartmendr.data_learner.active_learner import *\n",
    "from smartmendr.data_learner.models import DDL_Dataset \n",
    "from smartmendr.data_learner.lal_model import LALmodel\n",
    "\n",
    "fn = 'LAL-iterativetree-simulatedunbalanced-big.npz'\n",
    "parameters = {'est': 1000, 'depth': 40, 'feat': 6 }\n",
    "filename = '../smartmendr/data_learner/datasets/'+fn\n",
    "regression_data = np.load(filename)\n",
    "regression_features = regression_data['arr_0']\n",
    "regression_labels = regression_data['arr_1']\n",
    "lalModel = RandomForestRegressor(n_estimators = parameters['est'], max_depth = parameters['depth'], \n",
    "                                 max_features=parameters['feat'], oob_score=True, n_jobs=8)\n",
    "lalModel.fit(regression_features, np.ravel(regression_labels))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the dataset for DLL\n",
      "[[ 1.0000e+00  3.9000e+01  7.0000e+00 ...  4.0000e+01  3.9000e+01\n",
      "  -1.0000e+00]\n",
      " [ 2.0000e+00  5.0000e+01  6.0000e+00 ...  1.3000e+01  3.9000e+01\n",
      "  -1.0000e+00]\n",
      " [ 3.0000e+00  3.8000e+01  4.0000e+00 ...  4.0000e+01  3.9000e+01\n",
      "  -1.0000e+00]\n",
      " ...\n",
      " [ 2.6046e+04  3.2000e+01  4.0000e+00 ...  3.0000e+01  3.9000e+01\n",
      "  -1.0000e+00]\n",
      " [ 2.6047e+04  3.6000e+01  4.0000e+00 ...  4.0000e+01  3.9000e+01\n",
      "  -1.0000e+00]\n",
      " [ 2.6048e+04  4.1000e+01  7.0000e+00 ...  4.0000e+01  3.9000e+01\n",
      "  -1.0000e+00]]\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "from smartmendr.data_learner.dl_utils import *\n",
    "indices, labels= run_dll(lalModel, labeling_budget,df_active_learning);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_Results=pd.DataFrame(columns=['index','AL_Label'])\n",
    "AL_Results['index']=indices.astype('int64')\n",
    "AL_Results['AL_Label']=labels\n",
    "AL_Results = AL_Results.sort_values(by =['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_Results.loc[AL_Results['AL_Label']==0, 'AL_Label']=-1\n",
    "data_with_AL_Results = df_with_additional_info.merge(AL_Results, on=['index'], how='left')\n",
    "true_label = data_with_AL_Results['AL_Label']\n",
    "true_label = true_label.fillna(0)\n",
    "for i in range(len(true_label)):\n",
    "    if true_label[i] !=0:\n",
    "        L_train[i,:]=true_label[i]\n",
    "gen_model, AL_train_marginals = Fitting_Gen_Model(L_train)\n",
    "predictions = gen_model.predictions(L_train, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list\n",
    "noise_detection = Calculate_labeling_accuracy(0.5, columns_list, AL_train_marginals, DU)\n",
    "print(noise_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
